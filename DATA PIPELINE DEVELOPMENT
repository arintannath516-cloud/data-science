"""
CODTECH Data Science Internship
Task 2: Deep Learning Project

Project: Handwritten Digit Classification (MNIST)
Tools: TensorFlow, Keras, Matplotlib
Author: Arintan Nath
"""

# -----------------------------
# Import required libraries
# -----------------------------
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
import matplotlib.pyplot as plt

# -----------------------------
# Load the MNIST dataset
# -----------------------------
# It has 60k training images and 10k test images of digits 0-9
(X_train, y_train), (X_test, y_test) = mnist.load_data()

# -----------------------------
# Preprocessing
# -----------------------------
# Scale pixel values to [0,1] range
X_train = X_train / 255.0
X_test = X_test / 255.0

# CNN expects 4D input (samples, height, width, channels)
X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)
X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)

# -----------------------------
# Build the CNN model
# -----------------------------
model = Sequential()

# First conv layer
model.add(Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))
model.add(MaxPooling2D(pool_size=(2,2)))

# Second conv layer
model.add(Conv2D(64, (3,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

# Flatten + Dense layers
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(10, activation='softmax'))  # 10 classes for digits

# -----------------------------
# Compile the model
# -----------------------------
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# -----------------------------
# Train the model
# -----------------------------
# Using 5 epochs for demo, can increase for better accuracy
history = model.fit(X_train, y_train,
                    epochs=5,
                    validation_split=0.1)

# -----------------------------
# Evaluate on test data
# -----------------------------
test_loss, test_acc = model.evaluate(X_test, y_test)
print("Test accuracy:", test_acc)

# -----------------------------
# Plot accuracy curves
# -----------------------------
plt.plot(history.history['accuracy'], label='train acc')
plt.plot(history.history['val_accuracy'], label='val acc')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training vs Validation Accuracy')
plt.legend()
plt.show()

#visualizations of results
# =========================
# Save the trained model
# =========================
model.save("mnist_cnn_model.h5")

# =========================
# Plot Accuracy
# =========================
import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Model Accuracy')
plt.legend()
plt.show()

# =========================
# Plot Loss
# =========================
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Model Loss')
plt.legend()
plt.show()

# =========================
# Sample Predictions (Optional)
# =========================
import numpy as np

# Pick 5 random test samples
indices = np.random.choice(len(X_test), 5)
sample_images = X_test[indices]
sample_labels = y_test[indices]

predictions = model.predict(sample_images)

for i in range(5):
    plt.imshow(sample_images[i].reshape(28,28), cmap='gray')
    plt.title(f"True: {sample_labels[i]}, Predicted: {np.argmax(predictions[i])}")
    plt.axis('off')
    plt.show()
print("Task 2 completed")
